time <attribute 'day' of 'datetime.date' objects> <attribute 'hour' of 'datetime.datetime' objects>:0001-01-01 00:00:00main file: DDPG_main.pyplatform = Windows
episodes = 250
buffer size = 1000000
gamma = 0.99
tau = 0.001
learning rate actor = 0.001
learning rate critic = 0.001
device = cuda:0
learn every = 20
learn repeat x times = 10
(noise) sigma = 0.2
fc1,fc2 units = 400,300
 prior attempts used 128 fc1 and fc2 units
pre-fill the buffer with experiences from random actions
Score ([min, mean, max] over agents) for ep. 0: [0.00,0.00,0.0] 	T: 0:01(m:s)	Est remain: 0:04(h:m)
Score ([min, mean, max] over agents) for ep. 1: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:00(h:m)
Score ([min, mean, max] over agents) for ep. 2: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:00(h:m)
Score ([min, mean, max] over agents) for ep. 3: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:00(h:m)
Score ([min, mean, max] over agents) for ep. 4: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:00(h:m)
Score ([min, mean, max] over agents) for ep. 5: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:00(h:m)
Score ([min, mean, max] over agents) for ep. 6: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 7: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 8: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 9: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 10: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 11: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 12: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 13: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 14: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 15: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 16: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 17: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 18: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 19: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 20: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 21: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 22: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 23: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 24: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 25: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 26: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 27: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 28: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 29: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 30: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 31: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 32: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 33: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 34: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 35: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 36: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 37: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 38: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 39: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 40: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 41: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 42: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 43: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 44: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 45: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 46: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 47: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 48: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 49: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 50: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 51: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 52: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 53: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 54: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)
Score ([min, mean, max] over agents) for ep. 55: [0.00,0.00,0.0] 	T: 0:00(m:s)	Est remain: 0:01(h:m)