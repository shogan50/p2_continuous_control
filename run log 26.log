time :2018-12-24 07:12:25.062372main file: DDPG_main.pyplatform = Windows
episodes = 250
buffer size = 1000000
gamma = 0.99
tau = 0.001
learning rate actor = 0.001
learning rate critic = 0.001
device = cuda:0
learn every = 1
learn repeat x times = 5
(noise) sigma = 0.2
fc1,fc2 units = 400,300
Score ([min, mean, max] over agents) for ep. 0: [0.04,0.86,2.0] 	T: 3:27(m:s)	Est remain: 14:21(h:m)
Score ([min, mean, max] over agents) for ep. 1: [0.00,0.87,2.2] 	T: 3:26(m:s)	Est remain: 14:14(h:m)
Score ([min, mean, max] over agents) for ep. 2: [0.16,0.83,1.5] 	T: 3:28(m:s)	Est remain: 14:21(h:m)
Score ([min, mean, max] over agents) for ep. 3: [0.05,0.98,1.7] 	T: 3:27(m:s)	Est remain: 14:12(h:m)
Score ([min, mean, max] over agents) for ep. 4: [0.23,0.92,2.1] 	T: 3:30(m:s)	Est remain: 14:22(h:m)
Score ([min, mean, max] over agents) for ep. 5: [0.00,0.51,1.4] 	T: 3:30(m:s)	Est remain: 14:19(h:m)
Score ([min, mean, max] over agents) for ep. 6: [0.00,0.62,1.3] 	T: 3:32(m:s)	Est remain: 14:21(h:m)
Score ([min, mean, max] over agents) for ep. 7: [0.31,0.76,1.4] 	T: 3:33(m:s)	Est remain: 14:21(h:m)
Score ([min, mean, max] over agents) for ep. 8: [0.12,0.75,2.3] 	T: 3:33(m:s)	Est remain: 14:20(h:m)
Score ([min, mean, max] over agents) for ep. 9: [0.00,0.49,1.2] 	T: 3:32(m:s)	Est remain: 14:12(h:m)
Score ([min, mean, max] over agents) for ep. 10: [0.00,0.45,1.2] 	T: 3:38(m:s)	Est remain: 14:31(h:m)
Score ([min, mean, max] over agents) for ep. 11: [0.00,0.04,0.2] 	T: 3:43(m:s)	Est remain: 14:46(h:m)
Score ([min, mean, max] over agents) for ep. 12: [0.00,0.24,1.1] 	T: 3:55(m:s)	Est remain: 15:31(h:m)